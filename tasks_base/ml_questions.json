[
  {
    "id": 1,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "easy",
    "question": "Опишите задачу машинного обучения. Дайте определение объекту, целевой переменной, признакам, модели, функционалу ошибки.",
    "answer": "Задача машинного обучения — построение модели, которая по входным признакам объекта предсказывает целевую переменную. Объект — элемент выборки (например, клиент, изображение). Целевая переменная (target) — то, что нужно предсказать. Признаки (features) — характеристики объекта, используемые для предсказания. Модель — функция, преобразующая признаки в предсказание. Функционал ошибки (loss function) — мера качества модели, показывающая, насколько предсказания отличаются от истинных значений."
  },
  {
    "id": 2,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "easy",
    "question": "Чем отличается функция потерь от функционала ошибки?",
    "answer": "Функция потерь (loss function) измеряет ошибку на одном объекте — это разница между предсказанием и истинным значением для конкретного примера. Функционал ошибки — это агрегированная мера по всей выборке, обычно среднее значение функции потерь по всем объектам. Например, MSE — это функционал ошибки, а (y - ŷ)² — функция потерь для одного объекта."
  },
  {
    "id": 3,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "easy",
    "question": "Какие функции потерь используются при решении задачи регрессии?",
    "answer": "Основные функции потерь для регрессии: MSE (Mean Squared Error) — среднеквадратичная ошибка, штрафует большие ошибки сильнее; MAE (Mean Absolute Error) — средняя абсолютная ошибка, устойчива к выбросам; Huber Loss — комбинация MSE и MAE, квадратичная для малых ошибок и линейная для больших; Log-Cosh — логарифм гиперболического косинуса, гладкая версия MAE; MAPE — средняя абсолютная процентная ошибка для интерпретируемости."
  },
  {
    "id": 4,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "easy",
    "question": "Запишите формулу для линейной модели регрессии.",
    "answer": "Линейная регрессия: ŷ = w₀ + w₁x₁ + w₂x₂ + ... + wₙxₙ = w₀ + Σwᵢxᵢ, или в векторной форме: ŷ = w^T·x + b, где w — вектор весов, x — вектор признаков, b (или w₀) — свободный член (bias). Модель предполагает линейную зависимость целевой переменной от признаков."
  },
  {
    "id": 5,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Чем отличаются функционалы MSE и MAE? В каких случаях лучше использовать MSE, а в каких MAE?",
    "answer": "MSE = (1/n)Σ(yᵢ - ŷᵢ)² — квадратично штрафует ошибки, сильнее реагирует на выбросы, дифференцируема везде. MAE = (1/n)Σ|yᵢ - ŷᵢ| — линейно штрафует ошибки, устойчива к выбросам, не дифференцируема в нуле. MSE лучше использовать когда: важно сильно штрафовать большие ошибки, нет выбросов, нужна гладкость для оптимизации. MAE лучше когда: есть выбросы в данных, все ошибки одинаково важны, нужна интерпретируемость в единицах целевой переменной."
  },
  {
    "id": 6,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Что такое коэффициент детерминации R²? Как интерпретировать его значения?",
    "answer": "R² = 1 - (SS_res / SS_tot), где SS_res = Σ(yᵢ - ŷᵢ)² — сумма квадратов остатков, SS_tot = Σ(yᵢ - ȳ)² — общая сумма квадратов. R² показывает долю дисперсии целевой переменной, объяснённую моделью. Интерпретация: R² = 1 — идеальная модель; R² = 0 — модель не лучше среднего; R² < 0 — модель хуже простого среднего; R² ∈ (0, 1) — модель объясняет часть вариации. Например, R² = 0.8 означает, что модель объясняет 80% вариации данных."
  },
  {
    "id": 7,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Что такое градиент? Какое его свойство используется при минимизации функций?",
    "answer": "Градиент — вектор частных производных функции по всем переменным: ∇f = (∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ). Ключевое свойство: градиент указывает направление наискорейшего возрастания функции. Для минимизации используется антиградиент (-∇f), который указывает направление наискорейшего убывания. Это позволяет итеративно двигаться к минимуму: w_new = w_old - α·∇f(w_old), где α — шаг обучения (learning rate)."
  },
  {
    "id": 8,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Что такое градиентный спуск? Опишите процесс алгоритма.",
    "answer": "Градиентный спуск — итеративный алгоритм оптимизации для поиска минимума функции. Процесс: 1) Инициализация весов случайно или нулями; 2) Вычисление градиента функции потерь по весам; 3) Обновление весов: w = w - α·∇L(w), где α — learning rate; 4) Повторение шагов 2-3 до сходимости. Виды: полный (batch) — градиент по всей выборке; стохастический (SGD) — по одному объекту; мини-батч — по подвыборке. Критерии остановки: малое изменение loss, достижение числа итераций, малая норма градиента."
  },
  {
    "id": 9,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Что такое переобучение? Как можно отследить переобучение модели?",
    "answer": "Переобучение (overfitting) — ситуация, когда модель слишком хорошо запоминает обучающую выборку, включая шум, и плохо обобщает на новые данные. Признаки: высокое качество на train, низкое на test/validation. Способы отслеживания: 1) Разделение на train/validation/test; 2) Кросс-валидация; 3) Learning curves — графики ошибки на train и val от числа итераций; 4) Сравнение метрик train vs val. Борьба: регуляризация (L1, L2), dropout, early stopping, увеличение данных, уменьшение сложности модели."
  },
  {
    "id": 10,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Что такое регуляризация? Для чего используется?",
    "answer": "Регуляризация — добавление штрафа за сложность модели к функции потерь: L_reg = L + λ·R(w), где R(w) — регуляризатор, λ — коэффициент регуляризации. Цели: предотвращение переобучения, улучшение обобщающей способности, стабилизация решения. Интуиция: ограничивает величину весов, не давая модели подстраиваться под шум. Большие веса → сложная модель → переобучение. Регуляризация штрафует большие веса, заставляя модель быть проще."
  },
  {
    "id": 11,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "medium",
    "question": "Опишите, как работают L1- и L2-регуляризаторы.",
    "answer": "L1 (Lasso): R(w) = Σ|wᵢ| — сумма модулей весов. Приводит к разреженным решениям (многие веса = 0), выполняет отбор признаков. L2 (Ridge): R(w) = Σwᵢ² — сумма квадратов весов. Уменьшает все веса равномерно, не обнуляет их полностью. Геометрически: L1 — ограничение в виде ромба, решение часто в вершинах (нулевые веса); L2 — ограничение в виде шара, решение обычно не в точках с нулевыми координатами. ElasticNet комбинирует оба: λ₁Σ|wᵢ| + λ₂Σwᵢ²."
  },
  {
    "id": 12,
    "category": "ml-theory",
    "topic": "linear_models",
    "difficulty": "hard",
    "question": "Почему L1-регуляризация отбирает признаки?",
    "answer": "Геометрическая интерпретация: область допустимых решений L1 — ромб с вершинами на осях координат. Контуры функции потерь — эллипсы. Точка касания эллипса и ромба чаще всего находится в вершине ромба, где одна или несколько координат равны нулю. Для L2 область — шар, касание редко происходит на осях. Математически: субградиент |w| в нуле — интервал [-1, 1], что позволяет градиенту 'застрять' в нуле. У w² производная в нуле = 0, поэтому градиент всегда толкает от нуля."
  },
  {
    "id": 13,
    "category": "ml-theory",
    "topic": "classification",
    "difficulty": "easy",
    "question": "Что такое точность (Precision), полнота (Recall) и F-мера?",
    "answer": "Precision = TP / (TP + FP) — доля правильных среди предсказанных положительных. 'Насколько можно доверять положительным предсказаниям'. Recall = TP / (TP + FN) — доля найденных среди всех реальных положительных. 'Какую долю положительных нашли'. F1 = 2 · (Precision · Recall) / (Precision + Recall) — гармоническое среднее. F-мера лучше среднего арифметического, т.к. штрафует за дисбаланс: если P=1, R=0, то F1=0 (а не 0.5). Fβ с β>1 даёт больший вес Recall, β<1 — Precision."
  },
  {
    "id": 14,
    "category": "ml-theory",
    "topic": "classification",
    "difficulty": "medium",
    "question": "Что такое AUC-ROC? Опишите алгоритм построения ROC-кривой.",
    "answer": "ROC (Receiver Operating Characteristic) — график зависимости TPR от FPR при разных порогах классификации. TPR = TP/(TP+FN) = Recall; FPR = FP/(FP+TN). Построение: 1) Отсортировать объекты по убыванию score; 2) Перебирать пороги от макс до мин; 3) Для каждого порога вычислить TPR и FPR; 4) Построить точки (FPR, TPR). AUC-ROC — площадь под ROC-кривой. Интерпретация: вероятность того, что случайный положительный объект получит score выше случайного отрицательного. AUC=0.5 — случайная модель, AUC=1 — идеальная."
  },
  {
    "id": 15,
    "category": "ml-theory",
    "topic": "classification",
    "difficulty": "medium",
    "question": "Запишите функционал логистической регрессии. Как он связан с методом максимума правдоподобия?",
    "answer": "Логистическая регрессия: P(y=1|x) = σ(w^T·x) = 1/(1 + e^(-w^T·x)). Функционал — бинарная кросс-энтропия: L = -Σ[yᵢ·log(p̂ᵢ) + (1-yᵢ)·log(1-p̂ᵢ)]. Связь с MLE: предполагаем y ~ Bernoulli(p), правдоподобие L = Π p̂ᵢ^yᵢ · (1-p̂ᵢ)^(1-yᵢ). Логарифм правдоподобия: log L = Σ[yᵢ·log(p̂ᵢ) + (1-yᵢ)·log(1-p̂ᵢ)]. Максимизация log L эквивалентна минимизации -log L, что и есть кросс-энтропия. Таким образом, минимизация лосса = максимизация правдоподобия."
  },
  {
    "id": 16,
    "category": "ml-theory",
    "topic": "classification",
    "difficulty": "medium",
    "question": "Как бороться с дисбалансом классов?",
    "answer": "Методы борьбы с дисбалансом: 1) Взвешивание классов — увеличить вес редкого класса в loss; 2) Oversampling — увеличить редкий класс (SMOTE генерирует синтетические примеры); 3) Undersampling — уменьшить частый класс; 4) Изменение порога — сдвинуть threshold в пользу редкого класса; 5) Stratified split — сохранять пропорции при разбиении; 6) Специальные метрики — F1, AUC-PR вместо accuracy; 7) Ансамбли — bagging с balanced подвыборками; 8) Focal Loss — сильнее штрафует ошибки на сложных примерах."
  },
  {
    "id": 17,
    "category": "ml-theory",
    "topic": "trees",
    "difficulty": "easy",
    "question": "Что такое решающее дерево?",
    "answer": "Решающее дерево — модель, представляющая последовательность условий (if-then правил) в виде дерева. Внутренние узлы — условия (предикаты) вида 'признак < порог'. Листья — предсказания (класс или значение). Путь от корня к листу — цепочка условий для предсказания. Преимущества: интерпретируемость, работа с разными типами признаков, не требует масштабирования. Недостатки: склонность к переобучению, нестабильность (малые изменения данных → другое дерево), ступенчатые границы решений."
  },
  {
    "id": 18,
    "category": "ml-theory",
    "topic": "trees",
    "difficulty": "medium",
    "question": "Опишите жадный алгоритм обучения решающего дерева.",
    "answer": "Жадный алгоритм: 1) Начать с корня, содержащего все объекты; 2) Для текущего узла перебрать все признаки и пороги; 3) Выбрать разбиение, максимизирующее Information Gain (или минимизирующее impurity); 4) Создать дочерние узлы и распределить объекты; 5) Рекурсивно повторить для дочерних узлов; 6) Остановиться при: достижении max_depth, min_samples в узле, чистом узле (один класс). Критерии разбиения: Gini impurity, энтропия (для классификации), MSE, MAE (для регрессии). Жадность: на каждом шаге выбираем локально лучшее разбиение."
  },
  {
    "id": 19,
    "category": "ml-theory",
    "topic": "trees",
    "difficulty": "medium",
    "question": "Что такое критерий хаотичности? Как он используется для выбора предиката в решающем дереве?",
    "answer": "Критерий хаотичности (impurity) — мера неоднородности узла. Для классификации: Gini = 1 - Σpᵢ², Entropy = -Σpᵢ·log(pᵢ), где pᵢ — доля класса i. Для регрессии: MSE = Σ(yᵢ - ȳ)²/n. Information Gain = H(parent) - Σ(nᵢ/n)·H(childᵢ) — уменьшение хаотичности после разбиения. Алгоритм: для каждого признака и порога вычисляем IG, выбираем разбиение с максимальным IG. Чистый узел: Gini=0, Entropy=0 (все объекты одного класса)."
  },
  {
    "id": 20,
    "category": "ml-theory",
    "topic": "trees",
    "difficulty": "medium",
    "question": "В чем отличия энтропийного критерия и критерия Джини?",
    "answer": "Entropy = -Σpᵢ·log₂(pᵢ), Gini = 1 - Σpᵢ². Математически: энтропия — из теории информации, Джини — вероятность неправильной классификации случайного объекта. Практически: очень похожи, дают схожие деревья. Отличия: энтропия чуть медленнее (логарифм), Джини по умолчанию в sklearn. Энтропия более чувствительна к изменениям распределения классов. При двух классах: Gini_max = 0.5, Entropy_max = 1. Оба равны 0 для чистого узла. На практике выбор между ними редко влияет на качество."
  },
  {
    "id": 21,
    "category": "ml-theory",
    "topic": "ensembles",
    "difficulty": "medium",
    "question": "Что такое бэггинг? Как его смещение и разброс связаны со смещением и разбросом базовых моделей?",
    "answer": "Bagging (Bootstrap Aggregating): 1) Создать N bootstrap-выборок (с возвратом); 2) Обучить базовую модель на каждой; 3) Усреднить предсказания (регрессия) или голосование (классификация). Влияние на bias-variance: Bias ≈ такой же как у базовой модели (усреднение не уменьшает смещение); Variance уменьшается в ~N раз для независимых моделей. Поэтому bagging эффективен для моделей с низким bias и высоким variance (глубокие деревья). Для моделей с высоким bias (пни) bagging малоэффективен."
  },
  {
    "id": 22,
    "category": "ml-theory",
    "topic": "ensembles",
    "difficulty": "medium",
    "question": "Что такое случайный лес? Чем он отличается от бэггинга над решающими деревьями?",
    "answer": "Random Forest = Bagging + случайные подпространства признаков. Отличия от bagging: 1) При каждом разбиении узла рассматривается случайное подмножество признаков (обычно √p для классификации, p/3 для регрессии); 2) Деревья обучаются до конца (max_depth=None). Это дополнительно декоррелирует деревья, уменьшая variance ансамбля. Важные гиперпараметры: n_estimators (число деревьев), max_features (число признаков для разбиения), max_depth, min_samples_split. OOB-оценка — бесплатная валидация на ~37% объектов, не попавших в bootstrap."
  },
  {
    "id": 23,
    "category": "ml-theory",
    "topic": "ensembles",
    "difficulty": "hard",
    "question": "Чем отличается бустинг от бэггинга?",
    "answer": "Bagging: модели обучаются независимо и параллельно, затем усредняются. Уменьшает variance, не меняет bias. Boosting: модели обучаются последовательно, каждая исправляет ошибки предыдущих. Уменьшает bias. В бустинге: новая модель обучается на остатках (gradient boosting) или на перевзвешенной выборке (AdaBoost). Итоговое предсказание — взвешенная сумма. Boosting склонен к переобучению при большом числе итераций. Bagging хорошо параллелится, boosting — нет. Gradient Boosting (XGBoost, LightGBM, CatBoost) — state-of-the-art на табличных данных."
  },
  {
    "id": 24,
    "category": "ml-theory",
    "topic": "ensembles",
    "difficulty": "hard",
    "question": "Расскажите о градиентном бустинге. Как обучается новая модель?",
    "answer": "Gradient Boosting: ансамбль F(x) = Σαₘ·hₘ(x), где hₘ — базовые модели (обычно неглубокие деревья). Алгоритм: 1) F₀(x) = среднее/константа; 2) На итерации m: вычислить антиградиент loss по предсказаниям rₘ = -∂L/∂F_{m-1}(x) (псевдоостатки); 3) Обучить hₘ на (x, rₘ); 4) Fₘ = F_{m-1} + α·hₘ. Для MSE: rₘ = y - F_{m-1}(x) — просто остатки. Для других loss — соответствующий градиент. Learning rate α < 1 для регуляризации. Регуляризация: max_depth, min_samples, subsampling, L1/L2 на листья."
  },
  {
    "id": 25,
    "category": "ml-theory",
    "topic": "neural_networks",
    "difficulty": "medium",
    "question": "Что такое функция активации? Зачем она нужна?",
    "answer": "Функция активации — нелинейное преобразование выхода нейрона: a = σ(z), где z = w·x + b. Без активаций: композиция линейных функций — линейная функция, сеть не сможет моделировать нелинейные зависимости. Популярные активации: Sigmoid σ(x) = 1/(1+e^(-x)) — для вероятностей, проблема затухания градиента; Tanh — от -1 до 1, центрирован; ReLU max(0,x) — простой, быстрый, проблема 'мёртвых нейронов'; Leaky ReLU — решает проблему мёртвых нейронов; GELU, Swish — современные, гладкие."
  },
  {
    "id": 26,
    "category": "ml-theory",
    "topic": "neural_networks",
    "difficulty": "medium",
    "question": "Что такое обратное распространение ошибки (backpropagation)?",
    "answer": "Backpropagation — алгоритм вычисления градиентов loss по всем параметрам сети с помощью цепного правила. Этапы: 1) Forward pass: вычислить предсказания и loss; 2) Backward pass: вычислить градиенты от loss к параметрам. Для слоя l: ∂L/∂W_l = ∂L/∂z_l · ∂z_l/∂W_l, где ∂L/∂z_l вычисляется через градиенты следующих слоёв. Ключевая идея: переиспользование вычислений — градиент каждого слоя зависит только от градиентов следующих слоёв. Сложность O(n) — один проход вперёд, один назад."
  },
  {
    "id": 27,
    "category": "ml-theory",
    "topic": "neural_networks",
    "difficulty": "hard",
    "question": "Что такое Batch Normalization? Зачем она нужна?",
    "answer": "Batch Normalization нормализует активации внутри мини-батча: x̂ = (x - μ_B)/√(σ²_B + ε), y = γ·x̂ + β, где μ_B, σ²_B — среднее и дисперсия по батчу, γ, β — обучаемые параметры. Преимущества: 1) Ускоряет сходимость — позволяет использовать больший learning rate; 2) Регуляризация — добавляет шум через статистики батча; 3) Уменьшает internal covariate shift — стабилизирует распределение активаций. На инференсе используются скользящие средние μ, σ² по training. Альтернативы: Layer Norm (для трансформеров), Instance Norm (для стилей)."
  },
  {
    "id": 28,
    "category": "ml-theory",
    "topic": "neural_networks",
    "difficulty": "hard",
    "question": "Что такое Dropout? Как он работает?",
    "answer": "Dropout — техника регуляризации: во время обучения случайно 'выключаем' нейроны с вероятностью p. Каждый нейрон умножается на маску Bernoulli(1-p). На инференсе: все нейроны активны, выходы умножаются на (1-p) для сохранения масштаба (или inverted dropout — делим на 1-p при обучении). Интуиция: 1) Ансамбль — усреднение экспоненциального числа 'подсетей'; 2) Предотвращает ко-адаптацию нейронов — каждый должен быть полезен независимо. Типичные p: 0.5 для FC слоёв, 0.1-0.3 для сверточных. Не используется с Batch Norm (они оба — регуляризация)."
  },
  {
    "id": 29,
    "category": "ml-theory",
    "topic": "neural_networks",
    "difficulty": "hard",
    "question": "Что такое ResNet и зачем нужны skip-connections?",
    "answer": "ResNet (Residual Network) — архитектура с остаточными связями: y = F(x) + x, где F(x) — преобразование блока (conv-bn-relu-conv-bn). Skip-connection пропускает вход напрямую к выходу блока. Зачем нужны: 1) Решают проблему затухающего градиента — градиент может течь напрямую через skip; 2) Облегчают обучение глубоких сетей — сеть может 'выучить' identity (F(x)=0); 3) Позволяют строить сети в 100+ слоёв. Математически: ∂y/∂x = ∂F/∂x + 1 — градиент не может быть меньше 1. Варианты: ResNet-18/34/50/101/152, ResNeXt, DenseNet (все предыдущие слои)."
  },
  {
    "id": 30,
    "category": "ml-theory",
    "topic": "cnn",
    "difficulty": "medium",
    "question": "Что такое свёртка в контексте нейронных сетей?",
    "answer": "Свёртка — операция применения фильтра (ядра) к входному изображению: (I * K)(i,j) = ΣₘΣₙ I(i+m, j+n)·K(m,n). Ядро (kernel) — маленькая матрица весов (3×3, 5×5). Свёртка скользит по изображению, вычисляя скалярное произведение. Свойства: 1) Локальность — нейрон связан только с небольшой областью; 2) Разделение весов — одно ядро для всего изображения; 3) Эквивариантность к сдвигу — сдвиг входа сдвигает выход. Параметры: размер ядра, stride (шаг), padding (дополнение нулями), число фильтров (выходных каналов)."
  },
  {
    "id": 31,
    "category": "ml-theory",
    "topic": "cnn",
    "difficulty": "medium",
    "question": "Что такое пулинг (Pooling)? Какие виды пулинга существуют?",
    "answer": "Pooling — операция уменьшения размерности карты признаков, сохраняющая важную информацию. Виды: Max Pooling — выбирает максимум в окне, сохраняет наиболее выраженные признаки; Average Pooling — среднее в окне, сглаживает признаки; Global Average Pooling — среднее по всей карте, используется перед FC слоем. Параметры: размер окна (обычно 2×2), stride (обычно = размеру окна). Преимущества: уменьшает размерность, добавляет инвариантность к небольшим сдвигам, уменьшает переобучение. Современный тренд: strided convolution вместо pooling."
  },
  {
    "id": 32,
    "category": "ml-theory",
    "topic": "bias_variance",
    "difficulty": "medium",
    "question": "Что такое Bias-Variance Decomposition?",
    "answer": "Bias-Variance Decomposition разлагает ожидаемую ошибку модели: E[(y - ŷ)²] = Bias² + Variance + σ² (необратимый шум). Bias = E[ŷ] - y* — систематическая ошибка, насколько в среднем модель отклоняется от истины. Высокий bias = недообучение (underfitting). Variance = E[(ŷ - E[ŷ])²] — чувствительность к обучающей выборке. Высокий variance = переобучение (overfitting). Trade-off: простые модели — высокий bias, низкий variance; сложные — наоборот. Цель: найти баланс, минимизирующий общую ошибку."
  },
  {
    "id": 33,
    "category": "ml-theory",
    "topic": "bias_variance",
    "difficulty": "medium",
    "question": "Приведите пример семейства алгоритмов с низким смещением и большим разбросом. А с большим смещением и низким разбросом?",
    "answer": "Низкий bias, высокий variance (сложные, гибкие модели): глубокие решающие деревья без ограничений, k-NN с малым k, нейросети без регуляризации, полиномиальная регрессия высокой степени. Высокий bias, низкий variance (простые модели): линейная регрессия, логистическая регрессия, Naive Bayes, decision stumps (деревья глубины 1), k-NN с большим k. Практика: начинают с простых моделей (baseline), затем усложняют. Ансамбли: bagging уменьшает variance, boosting уменьшает bias."
  },
  {
    "id": 34,
    "category": "ml-theory",
    "topic": "metrics",
    "difficulty": "easy",
    "question": "Когда используется accuracy и почему она может быть плохой метрикой?",
    "answer": "Accuracy = (TP + TN) / (TP + TN + FP + FN) — доля правильных предсказаний. Проблема при дисбалансе классов: если 99% объектов класса 0, модель 'всегда 0' даёт accuracy=99%, но бесполезна для класса 1. Когда использовать: сбалансированные классы, все ошибки одинаково важны. Когда НЕ использовать: дисбаланс классов (fraud detection, медицина), разная цена ошибок (FP vs FN). Альтернативы: Precision, Recall, F1, AUC-ROC, AUC-PR, balanced accuracy = (TPR + TNR)/2."
  },
  {
    "id": 35,
    "category": "ml-theory",
    "topic": "practical",
    "difficulty": "medium",
    "question": "Расскажите про виды скейлинга данных. Зачем они нужны?",
    "answer": "Виды масштабирования: StandardScaler: z = (x - μ) / σ — среднее 0, std 1. Для нормально распределённых данных, чувствителен к выбросам. MinMaxScaler: z = (x - min) / (max - min) — в диапазон [0, 1]. Сохраняет распределение, чувствителен к выбросам. RobustScaler: z = (x - median) / IQR — устойчив к выбросам, использует медиану и межквартильный размах. Зачем нужно: 1) Градиентные методы быстрее сходятся при одинаковых масштабах; 2) Регуляризация работает корректно; 3) k-NN, SVM зависят от масштаба. Не нужно для деревьев!"
  },
  {
    "id": 36,
    "category": "ml-theory",
    "topic": "practical",
    "difficulty": "medium",
    "question": "Что такое mean-target encoding? Может ли он привести к переобучению?",
    "answer": "Mean Target Encoding — замена категориального признака средним значением target для каждой категории. Например, для города: Moscow → 0.7 (если 70% положительных в Moscow). Проблема переобучения: если категория встречается 1 раз, mean target = точный target → утечка информации. Решения: 1) Smoothing: (n·mean + m·global_mean) / (n + m); 2) LOO (Leave-One-Out): считать без текущего объекта; 3) Складки: кодировать на фолдах как при CV; 4) Добавление шума. CatBoost делает это автоматически с ordered target encoding."
  }
]






